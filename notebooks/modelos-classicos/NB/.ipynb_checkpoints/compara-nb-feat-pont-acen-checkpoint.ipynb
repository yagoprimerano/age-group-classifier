{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce62debc-bf37-4d18-85a9-dbd1069ebb20",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22df3ca1-3dbe-4119-a257-9e8412799283",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import  classification_report\n",
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40afdead-65da-429b-a50f-0502db5333fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from time import time\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb6979b-7bfd-4cf2-b1d1-f2d3307470b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c89ff5c-9986-4808-bcf4-8ef62fbaf133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import RFECV, RFE, SelectKBest\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "from sklearn.svm import SVC\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726dd049-2914-4e15-aa97-41f875bc5e6d",
   "metadata": {},
   "source": [
    "# Importação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f094c27-9803-45b7-927f-418b6a45133e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('../data/(CORRIGIDO)ep2_pln_train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b506f40-5b6f-47c4-9ed9-5def04c2904b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>req_text</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Quantos empregados em cada um dos atuais nív...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Solicito cópia das Atas do Conselho de Admin...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Solicito informar a norma (lei, decreto, por...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Solicito por gentileza, a informação sobre a...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Solicito por gentileza, a informação sobre a...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            req_text age\n",
       "0  - Quantos empregados em cada um dos atuais nív...  a2\n",
       "1  - Solicito cópia das Atas do Conselho de Admin...  a2\n",
       "2  - Solicito informar a norma (lei, decreto, por...  a2\n",
       "3  - Solicito por gentileza, a informação sobre a...  a2\n",
       "4  - Solicito por gentileza, a informação sobre a...  a2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # visualização das primeiras 5 linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f7a6c0-5b3a-4e1d-88aa-085d5b93d9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8200, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # visualização do formato do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c6d53f-17cb-4a87-8377-0fc88daf9fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "a3    3000\n",
       "a2    2000\n",
       "a4    2000\n",
       "a1    1200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ef30cb-c985-4221-b0fb-48e617b6732c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['age'] = data['age'].map({\n",
    "                                'a4':3,\n",
    "                                'a3': 2,\n",
    "                                'a2': 1,\n",
    "                                'a1': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4910bc1c-f52a-4bae-985f-a5282c1729a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>req_text</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Quantos empregados em cada um dos atuais nív...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Solicito cópia das Atas do Conselho de Admin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Solicito informar a norma (lei, decreto, por...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Solicito por gentileza, a informação sobre a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Solicito por gentileza, a informação sobre a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            req_text  age\n",
       "0  - Quantos empregados em cada um dos atuais nív...    1\n",
       "1  - Solicito cópia das Atas do Conselho de Admin...    1\n",
       "2  - Solicito informar a norma (lei, decreto, por...    1\n",
       "3  - Solicito por gentileza, a informação sobre a...    1\n",
       "4  - Solicito por gentileza, a informação sobre a...    1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c659419-4e04-45cc-88c3-dbbeec61d993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a seguir os dados serão divididos entre features (X) e label (y)\n",
    "X = data['req_text'] # features\n",
    "y = data['age'] # label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb5652-63fb-4fb7-b59f-16c9fbe8699a",
   "metadata": {},
   "source": [
    "# Seleção de hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383f61a-c05a-4c82-bdda-95a7856198ab",
   "metadata": {},
   "source": [
    "Nesta seção, será feita a comparação entre classificadores com os melhores hiperparâmetros encontrados através da utilização do otimizador Optuna, que, resumidamente, funciona de X forma. Os classificadores comparados são:\n",
    "- Regressão Logística\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "114a5435-f249-4ab4-aa5d-eb8adb732470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2843a037-0eae-458f-bca9-296fb683a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d4728-aaa3-4fed-8495-6a2feacba516",
   "metadata": {},
   "source": [
    "# Seleção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a72d42fd-ae47-4426-873d-24812b262f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleciona_grid(model):\n",
    "\n",
    "    param_grid = None\n",
    "\n",
    "    if isinstance(model, MultinomialNB):\n",
    "            param_grid = {\n",
    "            \"features__text__vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"features__text__vect__analyzer\": ['word','char'],\n",
    "            \"features__text__selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__alpha\": [50, 15, 10, 5, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.02, 0.01,  0.001],\n",
    "            \"estimator__fit_prior\": [True, False],\n",
    "            }\n",
    "\n",
    "    if isinstance(model, SVC):\n",
    "            param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'],\n",
    "            \"selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__gamma\": [1, 0.1, 0.01, 0.001],\n",
    "            \"estimator__kernel\": ['linear', 'sigmoid'],\n",
    "            \"estimator__C\": [0.1, 1, 10, 100]\n",
    "            }\n",
    "            \n",
    "    if isinstance(model, LinearSVC):\n",
    "            param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'],\n",
    "            \"selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__dual\": [True, False],\n",
    "            \"estimator__penalty\": ['l1', 'l2'],\n",
    "            \"estimator__fit_intercept\": [True, False],\n",
    "            \"estimator__C\": uniform(loc=0, scale=4)\n",
    "            }\n",
    "\n",
    "\n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "        param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'], \n",
    "            \"selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__n_estimators\": np.arange(20,150), \n",
    "            \"estimator__max_features\": ['log2', 'sqrt'],\n",
    "            \"estimator__max_depth\": np.arange(10,110),\n",
    "            \"estimator__min_samples_split\": np.arange(2,11),\n",
    "            \"estimator__min_samples_leaf\": np.arange(1,5),\n",
    "            \"estimator__bootstrap\": [True, False]\n",
    "            }\n",
    "        \n",
    "    if isinstance(model, XGBClassifier):\n",
    "        param_grid = {\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "            \"vect__analyzer\": ['word','char'],\n",
    "            \"selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__gamma\": np.linspace(0,9,100, dtype=np.int64),\n",
    "            \"estimator__alpha\": np.linspace(0,40,100, dtype=np.int64),\n",
    "            \"estimator__lambda\": np.linspace(0,3,10, dtype=np.int64),\n",
    "            \"estimator__colsample_bytree\": np.linspace(0.2,1,10, dtype=np.int64)\n",
    "            }\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04101a57-b165-4caa-a663-3f3395026b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_e_avalia(random_search):\n",
    "    \n",
    "    inicio_random_search = datetime.datetime.now()\n",
    "\n",
    "    model_trained = random_search.fit(X_train, y_train) # fit\n",
    "\n",
    "    fim_random_search = datetime.datetime.now()\n",
    "    tempo_total = fim_random_search - inicio_random_search\n",
    "    print(f'Duração da Random Search: {tempo_total}')\n",
    "\n",
    "    y_pred = model_trained.predict(X_test) # predicao\n",
    "\n",
    "    # Predição F1 e Class Report\n",
    "    f1 = f1_score(y_test, y_pred, average= 'macro') # f1\n",
    "    f1 *= 100\n",
    "    f1 = round(f1,2)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True) # class report\n",
    "    \n",
    "    return model_trained, tempo_total, f1, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cb3b510-e00a-470a-b40b-699a3fe87924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe personalizada para extrair as features de frequência de acentos e pontuação\n",
    "class CustomFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['frequencia_acentos'] = X_copy['req_text'].apply(lambda x: sum(1 for char in x if char in ['á', 'é', 'í', 'ó', 'ú', 'â', 'ê', 'î', 'ô', 'û']))\n",
    "        X_copy['frequencia_pontuacao'] = X_copy['req_text'].apply(lambda x: sum(1 for char in x if char in ['.', ',', ';', ':', '!', '?']))\n",
    "        return X_copy[['frequencia_acentos', 'frequencia_pontuacao']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32055d7b-f151-4e90-bf8a-3c8da39efe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara(iteracoes, modelos, nome_arquivo):\n",
    "\n",
    "    # seletor de features\n",
    "    selection = SelectPercentile()\n",
    "\n",
    "    # dataframe em que sera inserido os dados do modelo testado \n",
    "    df_resultados = pd.DataFrame(columns=['modelo', 'vect','sampler', 'scaling',\n",
    "                                          'duracao_random_search','qnt_iteracoes',\n",
    "                                          'f1_randsearch', \n",
    "                                           'f1_pred',\n",
    "                                          'class_report',\n",
    "                                         'duracao_aval_iv',\n",
    "                                          'acc_aval_iv',\n",
    "                                         'melhores_parametros'])\n",
    "    \n",
    "    for model in modelos:\n",
    "            \n",
    "        # seleciona grid de parametros\n",
    "        param_grid = seleciona_grid(model)\n",
    "          \n",
    "        scaler = MaxAbsScaler()\n",
    "\n",
    "        # Criando um pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('features', FeatureUnion([\n",
    "                ('text', Pipeline([\n",
    "                    ('vect', TfidfVectorizer()),\n",
    "                    ('scaling', scaler),\n",
    "                    ('selection', selection),\n",
    "                ])),\n",
    "                ('custom_features', CustomFeatureExtractor())\n",
    "            ])),\n",
    "            ('estimator', model)\n",
    "        ])\n",
    "            \n",
    "        # define o pipeline\n",
    "        #pipeline = Pipeline([\n",
    "        #        ('vect', TfidfVectorizer()),\n",
    "        #        ('scaling', scaler), \n",
    "        #        ('selection', selection),\n",
    "        #        ('ros', sampler),\n",
    "        #        ('estimator', model)\n",
    "        #        ])\n",
    "\n",
    "        \n",
    "        #  --- Prints das configurações dessa iteracao ---\n",
    "        print(f'Modelo: {model}')\n",
    "        #print(f'Split: {split}')\n",
    "        print(f'Scaler: {scaler}')\n",
    "        #print(f'Sampler: {sampler}')\n",
    "            \n",
    "\n",
    "        # definicao da randomized search\n",
    "        random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid,cv=StratifiedKFold(n_splits=5),\n",
    "                                            n_iter=iteracoes, n_jobs=1, random_state=42, scoring='f1_macro')\n",
    "\n",
    "\n",
    "        # fit e avaliacao pela randomized search\n",
    "        model_trained, tempo_total, f1, report = fit_e_avalia(random_search)\n",
    "            \n",
    "        print('---')\n",
    "        resultados = model_trained.cv_results_\n",
    "\n",
    "        for params, score in zip(resultados['params'], resultados['mean_test_score']):\n",
    "            print(f\"Parâmetros: {params}, Score: {score}\")\n",
    "        print('---')    \n",
    "            \n",
    "        # melhor metrica na random search\n",
    "        score_random_search = model_trained.best_score_\n",
    "        score_random_search *= 100\n",
    "        score_random_search = round(score_random_search,2)\n",
    "        print(f'Melhor F1 na Random Search: {score_random_search}%')\n",
    "        \n",
    "        # melhores parametros encontrados\n",
    "        print('Melhores parâmetros encontrados:')\n",
    "        print(model_trained.best_params_)\n",
    "\n",
    "        \n",
    "        # acuracia da predicao\n",
    "        print(f'F1 macro = {f1}%')\n",
    "\n",
    "        # classification report\n",
    "        print(report)\n",
    "\n",
    "        # Avaliação Ivandre\n",
    "        pipeline = Pipeline([\n",
    "                        ('vect', TfidfVectorizer()),\n",
    "                        ('scaling', scaler), \n",
    "                        ('selection', selection),\n",
    "                        ('ros', sampler),\n",
    "                        ('estimator', model)\n",
    "                        ])\n",
    "    \n",
    "        pipeline = pipeline.set_params(**model_trained.best_params_)\n",
    "    \n",
    "        print(f'get_params: {pipeline.get_params}')\n",
    "        \n",
    "        inicio_aval_iv = datetime.datetime.now()\n",
    "        acc_iv = cross_val_score(pipeline, X, y, scoring='accuracy', cv=10, n_jobs=2).mean()\n",
    "        acc_iv *= 100\n",
    "        acc_iv = round(acc_iv,2)\n",
    "        fim_aval_iv = datetime.datetime.now()\n",
    "        tempo_aval_iv = fim_aval_iv - inicio_aval_iv\n",
    "        print(f'Duração da Avaliação Ivandre: {tempo_aval_iv}')\n",
    "    \n",
    "        print(f'Acurácia Ivandre = {acc_iv}%')\n",
    "                \n",
    "        \n",
    "        print('----------------------------------------------')\n",
    "        \n",
    "        # --- Escrita em memória secundária ---\n",
    "\n",
    "        # Nova linha que sera adicionada\n",
    "        nova_linha = {'modelo': model, 'vect': TfidfVectorizer(),\n",
    "                      'sampler': 'aaaa', 'scaling': scaler,\n",
    "                      'duracao_random_search': tempo_total,\n",
    "                      'qnt_iteracoes': iteracoes,\n",
    "                      'f1_randsearch': f'{score_random_search}%',\n",
    "                      'f1_pred': f'{f1}%', 'class_report': report,\n",
    "                       'duracao_aval_iv': tempo_aval_iv,\n",
    "                       'acc_aval_iv': f'{acc_iv}%',\n",
    "                       'melhores_parametros': str(model_trained.best_params_)}\n",
    "    \n",
    "        # Cria um novo DataFrame com a nova linha\n",
    "        nova_linha_resultados = pd.DataFrame([nova_linha])\n",
    "    \n",
    "        # Concatena o novo DataFrame com o DataFrame existente\n",
    "        df_resultados = pd.concat([df_resultados, nova_linha_resultados], ignore_index=True)\n",
    "\n",
    "        # salvamento do dataframe de resultados apos os testes terem terminado\n",
    "        df_resultados.to_csv(nome_arquivo, index=False)\n",
    "\n",
    "\n",
    "    print('Fim dos testes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8b10544-c374-41c1-b1f1-ca475c27991e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['req_text', 'age'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdebdcbe-4a2e-41db-9663-5035c26935cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a0bde26-b65b-41f7-af08-268f7875e815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: MultinomialNB()\n",
      "Scaler: MaxAbsScaler()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'req_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3790\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3791\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'req_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9292\\469266710.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodelos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcompara\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'compara-nb-1-pont-acent.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9292\\3208045023.py\u001b[0m in \u001b[0;36mcompara\u001b[1;34m(iteracoes, modelos, nome_arquivo)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# fit e avaliacao pela randomized search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mmodel_trained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempo_total\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_e_avalia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9292\\3834582884.py\u001b[0m in \u001b[0;36mfit_e_avalia\u001b[1;34m(random_search)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minicio_random_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel_trained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfim_random_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \"\"\"\n\u001b[0;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[0msum\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mover\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \"\"\"\n\u001b[1;32m-> 1172\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parallel_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m             \u001b[1;31m# All transformers are None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_parallel_func\u001b[1;34m(self, X, y, fit_params, func)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mtransformers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1194\u001b[1;33m         return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m   1195\u001b[0m             delayed(func)(\n\u001b[0;32m   1196\u001b[0m                 \u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9292\\4089486281.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mX_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mX_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'frequencia_acentos'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'req_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'á'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'é'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'í'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ó'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ú'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'â'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ê'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'î'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ô'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'û'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mX_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'frequencia_pontuacao'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'req_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'!'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'?'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'frequencia_acentos'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'frequencia_pontuacao'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m         \u001b[1;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3795\u001b[0m             ):\n\u001b[0;32m   3796\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3797\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3798\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3799\u001b[0m             \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'req_text'"
     ]
    }
   ],
   "source": [
    "modelos = [MultinomialNB()]\n",
    "\n",
    "compara(1, modelos, 'compara-nb-1-pont-acent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447b4345-223a-42f1-a823-f543697088fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'0': {'precision': 0.3611111111111111, 'recall': 0.5416666666666666, 'f1-score': 0.43333333333333335, 'support': 240}, '1': {'precision': 0.4290718038528897, 'recall': 0.6125, 'f1-score': 0.5046343975283213, 'support': 400}, '2': {'precision': 0.5516431924882629, 'recall': 0.39166666666666666, 'f1-score': 0.4580896686159844, 'support': 600}, '3': {'precision': 0.6289752650176679, 'recall': 0.445, 'f1-score': 0.5212298682284041, 'support': 400}, 'accuracy': 0.48048780487804876, 'macro avg': {'precision': 0.4927003431174829, 'recall': 0.49770833333333336, 'f1-score': 0.47932181692651077, 'support': 1640}, 'weighted avg': {'precision': 0.5127264693340532, 'recall': 0.48048780487804876, 'f1-score': 0.48121921187334193, 'support': 1640}}\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv('compara-nb-240-.csv')\n",
    "results.class_report.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4f801d6-faa9-4cf9-ad72-5696a849a363",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yyy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11624\\2960058288.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myyy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'yyy' is not defined"
     ]
    }
   ],
   "source": [
    "yyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adcb47a-8444-4f1f-828b-9a68914b6f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d7986-e657-4bd4-9906-6af0e66c0206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa7f3f-4a9a-47cb-a926-91069188e7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b319ae76-aad6-44dd-97fe-dc2a07159af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31550b8e-4684-401b-b4ac-e1cb5f04ce1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compara(iteracoes):\n",
    "    \n",
    "    # Escrita no arquivo\n",
    "    with open('compara-xg-rf.txt', \"w\") as arquivo:\n",
    "        pass\n",
    "    \n",
    "    modelos = [XGBClassifier(seed=42),RandomForestClassifier(random_state=42)]\n",
    "    \n",
    "    vect = [CountVectorizer(analyzer='word'), TfidfVectorizer(analyzer= 'word')]\n",
    "    \n",
    "    for model in modelos:\n",
    "        \n",
    "        for vectorizer in vect:\n",
    "    \n",
    "            param_grid = None\n",
    "            \n",
    "            scaler = MaxAbsScaler()\n",
    "\n",
    "            preprocessor = ColumnTransformer(transformers=[\n",
    "                                            ('vect_resp_text', vectorizer,'resp_text'), \n",
    "                                            ('vect_pos', vectorizer,'pos')])\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                    ('preprocessor', preprocessor), \n",
    "                    ('scaling', scaler), \n",
    "                    ('estimator', model)\n",
    "                    ])\n",
    "\n",
    "            if isinstance(model, MultinomialNB):\n",
    "                param_grid = {\n",
    "                \"preprocessor__vect_resp_text__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                \"preprocessor__vect_pos__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                \"estimator__alpha\": [50, 15, 10, 5, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.02, 0.01,  0.001],\n",
    "                \"estimator__fit_prior\": [True, False],\n",
    "                }\n",
    "\n",
    "            if isinstance(model, SVC):\n",
    "                param_grid = {\n",
    "                \"preprocessor__vect_resp_text__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                \"preprocessor__vect_pos__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                \"estimator__gamma\": [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                \"estimator__kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                \"estimator__C\": [0.1, 1, 10, 100, 1000]\n",
    "                }\n",
    "\n",
    "            if isinstance(model, LogisticRegression):\n",
    "\n",
    "                if 'l1' in model.get_params()['penalty']:\n",
    "                    param_grid = {\n",
    "                    \"preprocessor__vect_resp_text__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                    \"preprocessor__vect_pos__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                    \"estimator__C\": np.linspace(0,10,100),\n",
    "                    \"estimator__solver\": ['liblinear','saga']\n",
    "                    }\n",
    "\n",
    "                elif 'l2' in model.get_params()['penalty']:\n",
    "                    param_grid = {\n",
    "                    \"preprocessor__vect_resp_text__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                    \"preprocessor__vect_pos__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                    \"estimator__C\": np.linspace(0,10,100),\n",
    "                    \"estimator__solver\": ['lbfgs', 'newton-cg', 'newton-cholesky',\n",
    "                                          'liblinear','saga', 'sag']\n",
    "                    }\n",
    "\n",
    "            if isinstance(model, RandomForestClassifier):\n",
    "                param_grid = {\n",
    "                \"preprocessor__vect_resp_text__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                \"preprocessor__vect_pos__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                \"estimator__n_estimators\": np.arange(20,150), \n",
    "                \"estimator__max_features\": ['log2', 'sqrt'],\n",
    "                \"estimator__max_depth\": np.arange(10,110),\n",
    "                \"estimator__min_samples_split\": np.arange(2,11),\n",
    "                \"estimator__min_samples_leaf\": np.arange(1,5),\n",
    "                \"estimator__bootstrap\": [True, False]\n",
    "                }\n",
    "                \n",
    "            if isinstance(model, XGBClassifier):\n",
    "                param_grid = {\n",
    "                \"preprocessor__vect_resp_text__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                \"preprocessor__vect_pos__ngram_range\": [(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)],\n",
    "                \"estimator__gamma\": np.linspace(0,9,100, dtype=np.int64),\n",
    "                \"estimator__alpha\": np.linspace(0,40,100, dtype=np.int64),\n",
    "                \"estimator__lambda\": np.linspace(0,3,10, dtype=np.int64),\n",
    "                \"estimator__colsample_bytree\": np.linspace(0.2,1,10, dtype=np.int64)\n",
    "                }\n",
    "\n",
    "                \n",
    "                \n",
    "            # Prints do modelo e da vetorização\n",
    "            if isinstance(model, LogisticRegression):\n",
    "                if 'l1' in model.get_params()['penalty']:\n",
    "                    print(f'Modelo: {model} l1')\n",
    "                else:\n",
    "                    print(f'Modelo: {model} l2')\n",
    "            else:\n",
    "                print(f'Modelo: {model}')\n",
    "                \n",
    "            print(f'Vetorizador utilizado: {vectorizer}')\n",
    "            \n",
    "            # Random Search\n",
    "            comeco_random_search = datetime.datetime.now()\n",
    "            print(f'Começo da Random Search: {comeco_random_search}')\n",
    "                \n",
    "            random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid,cv=StratifiedKFold(n_splits=5),\n",
    "                                                n_iter=iteracoes, n_jobs=2, random_state=24)\n",
    "            \n",
    "            model_trained = random_search.fit(X_train, y_train)\n",
    "\n",
    "            final_random_search = datetime.datetime.now()\n",
    "            print(f'Final da Random Search: {final_random_search}')\n",
    "            \n",
    "            score_random_search = model_trained.best_score_\n",
    "            score_random_search *= 100\n",
    "            score_random_search = round(score_random_search,2)\n",
    "            print(f'Melhor resultado na Random Search: {score_random_search}%')\n",
    "            \n",
    "            print('Melhores parâmetros encontrados:')\n",
    "            print(model_trained.best_params_)\n",
    "            \n",
    "            # Predição\n",
    "            y_pred = model_trained.predict(X_test)\n",
    "            acc_pred = accuracy_score(y_test, y_pred)\n",
    "            acc_pred *= 100\n",
    "            acc_pred = round(acc_pred,2)\n",
    "            print(f'Acurácia predita = {acc_pred}%')\n",
    "                    \n",
    "            # Avaliação Ivandre\n",
    "            comeco_av_iv = datetime.datetime.now()\n",
    "            print(f'Começo da Avaliação Ivandre: {comeco_av_iv}')\n",
    "            acc_iv = cross_val_score(model_trained, X, y, scoring='accuracy', cv=10, n_jobs=2).mean()\n",
    "            acc_iv *= 100\n",
    "            acc_iv = round(acc_iv,2)\n",
    "            final_av_iv = datetime.datetime.now()\n",
    "            print(f'Final da Avaliação Ivandre: {final_av_iv}')\n",
    "        \n",
    "            print(f'Acurácia Ivandre = {acc_iv}%')\n",
    "            \n",
    "            print('----------------------------------------------')\n",
    "            \n",
    "            # Escrita no arquivo\n",
    "            with open('compara-xg-rf.txt', \"a\") as arquivo:\n",
    "                \n",
    "                if isinstance(model, LogisticRegression):\n",
    "                    if 'l1' in model.get_params()['penalty']:\n",
    "                        arquivo.write(f'Modelo: {model} l1\\n')\n",
    "                    else:\n",
    "                        arquivo.write(f'Modelo: {model} l2\\n')\n",
    "                else:\n",
    "                    arquivo.write(f'Modelo: {model}\\n')\n",
    "\n",
    "                arquivo.write(f'Vetorizador utilizado: {vectorizer}\\n')\n",
    "                \n",
    "                arquivo.write(f'Começo da Random Search: {comeco_random_search}\\n')\n",
    "                arquivo.write(f'Final da Random Search: {final_random_search}\\n')\n",
    "                arquivo.write(f'Melhor resultado na Random Search: {score_random_search}\\n')\n",
    "                arquivo.write('Melhores parâmetros encontrados:\\n')\n",
    "                arquivo.write(str(model_trained.best_params_))\n",
    "                arquivo.write('\\n')\n",
    "                arquivo.write(f'Acurácia predita = {acc_pred}%\\n')\n",
    "                arquivo.write(f'Começo da Avaliação Ivandre: {comeco_av_iv}\\n')\n",
    "                arquivo.write(f'Final da Avaliação Ivandre: {final_av_iv}\\n')\n",
    "                arquivo.write(f'Acurácia Ivandre = {acc_iv}%\\n')\n",
    "                arquivo.write('----------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c646da-ded2-42f1-91b6-6ecf392bddbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compara(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
