{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce62debc-bf37-4d18-85a9-dbd1069ebb20",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22df3ca1-3dbe-4119-a257-9e8412799283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import  classification_report\n",
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40afdead-65da-429b-a50f-0502db5333fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from time import time\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c89ff5c-9986-4808-bcf4-8ef62fbaf133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import RFECV, RFE, SelectKBest\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "from sklearn.svm import SVC\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726dd049-2914-4e15-aa97-41f875bc5e6d",
   "metadata": {},
   "source": [
    "# Importação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f094c27-9803-45b7-927f-418b6a45133e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../../../data/processed/(CORRIGIDO)ep2_pln_train_pos_pt_core_news_lg.xlsx')\n",
    "data.drop(['Unnamed: 0', 'pos'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b506f40-5b6f-47c4-9ed9-5def04c2904b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>req_text</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Quantos empregados em cada um dos atuais nív...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Solicito cópia das Atas do Conselho de Admin...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Solicito informar a norma (lei, decreto, por...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Solicito por gentileza, a informação sobre a...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Solicito por gentileza, a informação sobre a...</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            req_text age\n",
       "0  - Quantos empregados em cada um dos atuais nív...  a2\n",
       "1  - Solicito cópia das Atas do Conselho de Admin...  a2\n",
       "2  - Solicito informar a norma (lei, decreto, por...  a2\n",
       "3  - Solicito por gentileza, a informação sobre a...  a2\n",
       "4  - Solicito por gentileza, a informação sobre a...  a2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # visualização das primeiras 5 linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f7a6c0-5b3a-4e1d-88aa-085d5b93d9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8200, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # visualização do formato do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c6d53f-17cb-4a87-8377-0fc88daf9fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "a3    3000\n",
       "a2    2000\n",
       "a4    2000\n",
       "a1    1200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2ef30cb-c985-4221-b0fb-48e617b6732c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['age'] = data['age'].map({\n",
    "                                'a4':3,\n",
    "                                'a3': 2,\n",
    "                                'a2': 1,\n",
    "                                'a1': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4910bc1c-f52a-4bae-985f-a5282c1729a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>req_text</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Quantos empregados em cada um dos atuais nív...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Solicito cópia das Atas do Conselho de Admin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Solicito informar a norma (lei, decreto, por...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Solicito por gentileza, a informação sobre a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Solicito por gentileza, a informação sobre a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            req_text  age\n",
       "0  - Quantos empregados em cada um dos atuais nív...    1\n",
       "1  - Solicito cópia das Atas do Conselho de Admin...    1\n",
       "2  - Solicito informar a norma (lei, decreto, por...    1\n",
       "3  - Solicito por gentileza, a informação sobre a...    1\n",
       "4  - Solicito por gentileza, a informação sobre a...    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c659419-4e04-45cc-88c3-dbbeec61d993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a seguir os dados serão divididos entre features (X) e label (y)\n",
    "X = data['req_text'] # features\n",
    "y = data['age'] # label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb5652-63fb-4fb7-b59f-16c9fbe8699a",
   "metadata": {},
   "source": [
    "# Seleção de hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383f61a-c05a-4c82-bdda-95a7856198ab",
   "metadata": {},
   "source": [
    "Nesta seção, será feita a comparação entre classificadores com os melhores hiperparâmetros encontrados através da utilização do otimizador Optuna, que, resumidamente, funciona de X forma. Os classificadores comparados são:\n",
    "- Regressão Logística\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "114a5435-f249-4ab4-aa5d-eb8adb732470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2843a037-0eae-458f-bca9-296fb683a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d4728-aaa3-4fed-8495-6a2feacba516",
   "metadata": {},
   "source": [
    "# Seleção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a72d42fd-ae47-4426-873d-24812b262f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleciona_grid(model):\n",
    "\n",
    "    param_grid = None\n",
    "\n",
    "    if isinstance(model, MultinomialNB):\n",
    "            param_grid = {\n",
    "            \"vect__analyzer\": ['word', 'char'],\n",
    "            \"vect__ngram_range\": [(1,2), (1,3), (1,4), (1,5), (1,6), (2,3), (2,4), (2,5), (2,6),\n",
    "                                  (3,4), (3,5), (3,6), (4,5), (4,6), (5,6)],\n",
    "            \"selection__percentile\": [33, 66, 100],\n",
    "            \"estimator__alpha\": [50, 15, 10, 5, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.02, 0.01,  0.001],\n",
    "            \"estimator__fit_prior\": [True, False],\n",
    "            }\n",
    "\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04101a57-b165-4caa-a663-3f3395026b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_e_avalia(random_search):\n",
    "    \n",
    "    inicio_random_search = datetime.datetime.now()\n",
    "\n",
    "    model_trained = random_search.fit(X_train, y_train) # fit\n",
    "\n",
    "    fim_random_search = datetime.datetime.now()\n",
    "    tempo_total = fim_random_search - inicio_random_search\n",
    "    print(f'Duração da Search: {tempo_total}')\n",
    "\n",
    "    y_pred = model_trained.predict(X_test) # predicao\n",
    "\n",
    "    # Predição F1 e Class Report\n",
    "    f1 = f1_score(y_test, y_pred, average= 'macro') # f1\n",
    "    f1 *= 100\n",
    "    f1 = round(f1,2)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True) # class report\n",
    "    \n",
    "    return model_trained, tempo_total, f1, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32055d7b-f151-4e90-bf8a-3c8da39efe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara(iteracoes, modelos, nome_arquivo):\n",
    "\n",
    "    # seletor de features\n",
    "    selection = SelectPercentile()\n",
    "\n",
    "    # possibilidades de oversampling ou nao\n",
    "    samplers = [RandomOverSampler(random_state=42), None]\n",
    "\n",
    "    # dataframe em que sera inserido os dados do modelo testado \n",
    "    df_resultados = pd.DataFrame(columns=['modelo', 'vect', 'sampler', 'scaling',\n",
    "                                          'duracao_search','qnt_iteracoes',\n",
    "                                          'f1_search', \n",
    "                                           'f1_pred',\n",
    "                                          'class_report',\n",
    "                                         'duracao_aval_iv',\n",
    "                                          'acc_aval_iv',\n",
    "                                         'melhores_parametros'])\n",
    "    \n",
    "    for model in modelos:\n",
    "\n",
    "        for sampler in samplers:\n",
    "\n",
    "                \n",
    "            # seleciona grid de parametros\n",
    "            param_grid = seleciona_grid(model)\n",
    "            \n",
    "            \n",
    "            scaler = MaxAbsScaler()\n",
    "    \n",
    "            # define o pipeline\n",
    "            pipeline = Pipeline([\n",
    "                    ('vect', TfidfVectorizer()),\n",
    "                    ('scaling', scaler), \n",
    "                    ('selection', selection),\n",
    "                    ('ros', sampler),\n",
    "                    ('estimator', model)\n",
    "                    ])\n",
    "    \n",
    "            \n",
    "            #  --- Prints das configurações dessa iteracao ---\n",
    "            print(f'Modelo: {model}')\n",
    "            print(f'Scaler: {scaler}')\n",
    "            print(f'Sampler: {sampler}')\n",
    "                \n",
    "    \n",
    "            # definicao da randomized search\n",
    "            random_search = GridSearchCV(pipeline, param_grid=param_grid,\n",
    "                                            cv=StratifiedKFold(n_splits=5), n_jobs=-1,\n",
    "                                            scoring='f1_macro',verbose=4)\n",
    "    \n",
    "    \n",
    "            # fit e avaliacao pela randomized search\n",
    "            model_trained, tempo_total, f1, report = fit_e_avalia(random_search)\n",
    "                \n",
    "            print('---')\n",
    "            resultados = model_trained.cv_results_\n",
    "    \n",
    "            for params, score in zip(resultados['params'], resultados['mean_test_score']):\n",
    "                print(f\"Parâmetros: {params}, Score: {score}\")\n",
    "            print('---')    \n",
    "                \n",
    "            # melhor metrica na random search\n",
    "            score_random_search = model_trained.best_score_\n",
    "            score_random_search *= 100\n",
    "            score_random_search = round(score_random_search,2)\n",
    "            print(f'Melhor F1 na Search: {score_random_search}%')\n",
    "            \n",
    "            # melhores parametros encontrados\n",
    "            print('Melhores parâmetros encontrados:')\n",
    "            print(model_trained.best_params_)\n",
    "    \n",
    "            \n",
    "            # acuracia da predicao\n",
    "            print(f'F1 macro = {f1}%')\n",
    "    \n",
    "            # classification report\n",
    "            print(report)\n",
    "    \n",
    "            # Avaliação Ivandre\n",
    "            pipeline = Pipeline([\n",
    "                            ('vect', TfidfVectorizer()),\n",
    "                            ('scaling', scaler), \n",
    "                            ('selection', selection),\n",
    "                            ('ros', sampler),\n",
    "                            ('estimator', model)\n",
    "                            ])\n",
    "        \n",
    "            pipeline = pipeline.set_params(**model_trained.best_params_)\n",
    "        \n",
    "            print(f'get_params: {pipeline.get_params}')\n",
    "            \n",
    "            inicio_aval_iv = datetime.datetime.now()\n",
    "            acc_iv = cross_val_score(pipeline, X, y, scoring='accuracy', cv=10, n_jobs=2).mean()\n",
    "            acc_iv *= 100\n",
    "            acc_iv = round(acc_iv,2)\n",
    "            fim_aval_iv = datetime.datetime.now()\n",
    "            tempo_aval_iv = fim_aval_iv - inicio_aval_iv\n",
    "            print(f'Duração da Avaliação Ivandre: {tempo_aval_iv}')\n",
    "        \n",
    "            print(f'Acurácia Ivandre = {acc_iv}%')\n",
    "                    \n",
    "            \n",
    "            print('----------------------------------------------')\n",
    "            \n",
    "            # --- Escrita em memória secundária ---\n",
    "    \n",
    "            # Nova linha que sera adicionada\n",
    "            nova_linha = {'modelo': model, 'vect': TfidfVectorizer(),\n",
    "                        'sampler': str(sampler), 'scaling': scaler,\n",
    "                          'duracao_search': tempo_total,\n",
    "                          'qnt_iteracoes': iteracoes,\n",
    "                          'f1_search': f'{score_random_search}%',\n",
    "                          'f1_pred': f'{f1}%', 'class_report': report,\n",
    "                           'duracao_aval_iv': tempo_aval_iv,\n",
    "                           'acc_aval_iv': f'{acc_iv}%',\n",
    "                           'melhores_parametros': str(model_trained.best_params_)}\n",
    "        \n",
    "            # Cria um novo DataFrame com a nova linha\n",
    "            nova_linha_resultados = pd.DataFrame([nova_linha])\n",
    "        \n",
    "            # Concatena o novo DataFrame com o DataFrame existente\n",
    "            df_resultados = pd.concat([df_resultados, nova_linha_resultados], ignore_index=True)\n",
    "    \n",
    "            # salvamento do dataframe de resultados apos os testes terem terminado\n",
    "            df_resultados.to_csv(nome_arquivo, index=False)\n",
    "\n",
    "\n",
    "    print('Fim dos testes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bde26-b65b-41f7-af08-268f7875e815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: MultinomialNB()\n",
      "Scaler: MaxAbsScaler()\n",
      "Sampler: RandomOverSampler(random_state=42)\n",
      "Fitting 5 folds for each of 2340 candidates, totalling 11700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\parallel.py\", line 938, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\concurrent\\futures\\_base.py\", line 441, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\yagoa\\AppData\\Local\\Temp\\ipykernel_12188\\1042163160.py\", line 3, in <module>\n",
      "    compara(iteracoes, modelos, 'nb-texto-' + str(iteracoes) + '.csv')\n",
      "  File \"C:\\Users\\yagoa\\AppData\\Local\\Temp\\ipykernel_12188\\2598623384.py\", line 53, in compara\n",
      "    model_trained, tempo_total, f1, report = fit_e_avalia(random_search)\n",
      "  File \"C:\\Users\\yagoa\\AppData\\Local\\Temp\\ipykernel_12188\\3626096956.py\", line 5, in fit_e_avalia\n",
      "    model_trained = random_search.fit(X_train, y_train) # fit\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 891, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 1392, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 838, in evaluate_candidates\n",
      "    out = parallel(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\parallel.py\", line 1061, in __call__\n",
      "    self.retrieve()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\parallel.py\", line 960, in retrieve\n",
      "    backend.abort_everything(ensure_ready=ensure_ready)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 561, in abort_everything\n",
      "    self._workers.terminate(kill_workers=True)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\executor.py\", line 74, in terminate\n",
      "    self.shutdown(kill_workers=kill_workers)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1185, in shutdown\n",
      "    executor_manager_thread.join()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "FileNotFoundError: [WinError 3] O sistema não pode encontrar o caminho especificado: 'C:\\\\Users\\\\yagoa\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_12188\\\\1042163160.py'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\inspect.py\", line 706, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 72, in checkcache\n",
      "    stat = os.stat(fullname)\n",
      "FileNotFoundError: [WinError 3] O sistema não pode encontrar o caminho especificado: 'C:\\\\Users\\\\yagoa\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_12188\\\\3626096956.py'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1079, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1116, in get_records\n",
      "    traceback.print_exc(file=self.ostream)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 163, in print_exc\n",
      "    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 103, in print_exception\n",
      "    for line in TracebackException(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 495, in __init__\n",
      "    context = TracebackException(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 495, in __init__\n",
      "    context = TracebackException(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 495, in __init__\n",
      "    context = TracebackException(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 517, in __init__\n",
      "    self.stack = StackSummary.extract(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 362, in extract\n",
      "    linecache.checkcache(filename)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\compilerop.py\", line 185, in check_linecache_ipython\n",
      "    linecache._checkcache_ori(*args)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 72, in checkcache\n",
      "    stat = os.stat(fullname)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2092, in showtraceback\n",
      "    print('\\n' + self.get_exception_only(), file=sys.stderr)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2037, in get_exception_only\n",
      "    msg = traceback.format_exception_only(etype, value)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 140, in format_exception_only\n",
      "    return list(TracebackException(etype, value, None).format_exception_only())\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 533, in __init__\n",
      "    self._load_lines()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 545, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 545, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 543, in _load_lines\n",
      "    frame.line\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 30, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 46, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\tokenize.py\", line 392, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\inspect.py\", line 745, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2079, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1079, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1115, in get_records\n",
      "    inspect_error()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 152, in inspect_error\n",
      "    error('Internal Python error in the inspect module.\\n'\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\logging\\__init__.py\", line 2064, in error\n",
      "    root.error(msg, *args, **kwargs)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\logging\\__init__.py\", line 1475, in error\n",
      "    self._log(ERROR, msg, args, **kwargs)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\logging\\__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\logging\\__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\logging\\__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\logging\\__init__.py\", line 952, in handle\n",
      "    self.emit(record)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\logging\\__init__.py\", line 1086, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\ipykernel\\iostream.py\", line 610, in write\n",
      "    self._schedule_flush()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\ipykernel\\iostream.py\", line 507, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\ipykernel\\iostream.py\", line 213, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\zmq\\sugar\\socket.py\", line 688, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq\\backend\\cython\\socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq\\backend\\cython\\socket.pyx\", line 789, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq\\backend\\cython\\socket.pyx\", line 250, in zmq.backend.cython.socket._send_copy\n",
      "  File \"zmq\\backend\\cython\\checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2092, in showtraceback\n",
      "    print('\\n' + self.get_exception_only(), file=sys.stderr)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2037, in get_exception_only\n",
      "    msg = traceback.format_exception_only(etype, value)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 140, in format_exception_only\n",
      "    return list(TracebackException(etype, value, None).format_exception_only())\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 533, in __init__\n",
      "    self._load_lines()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 545, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 545, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 545, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  [Previous line repeated 6 more times]\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 543, in _load_lines\n",
      "    frame.line\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 30, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 46, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 137, in updatecache\n",
      "    lines = fp.readlines()\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\codecs.py\", line 321, in decode\n",
      "    data = self.buffer + input\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\inspect.py\", line 1505, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 46, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"D:\\Downloads2\\Anaconda\\download\\lib\\tokenize.py\", line 392, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "modelos = [MultinomialNB()]\n",
    "iteracoes = 'grid'\n",
    "compara(iteracoes, modelos, 'nb-texto-' + str(iteracoes) + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
