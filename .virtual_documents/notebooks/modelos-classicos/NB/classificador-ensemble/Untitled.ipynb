import pandas as pd 

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import MaxAbsScaler
from sklearn.pipeline import Pipeline
#from imblearn.pipeline import Pipeline
from imblearn.over_sampling import RandomOverSampler
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import  classification_report
from sklearn.feature_selection import SelectPercentile


#imports
from time import time
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.svm import SVC
#from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import cross_val_score
import optuna
from sklearn.metrics import f1_score



from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier 
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.svm import LinearSVC
import nltk
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import RFECV, RFE, SelectKBest
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.model_selection import RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn import set_config
set_config(display='diagram')
from sklearn.svm import SVC
import datetime
from sklearn.ensemble import StackingClassifier





data = pd.read_csv('../../../../data/processed/(CORRIGIDO)ep2_pln_train_pos_pt_core_news_lg.xlsx')
data.drop(['Unnamed: 0'], axis=1, inplace=True)
data.head()


data['age'] = data['age'].map({
                                'a4':3,
                                'a3': 2,
                                'a2': 1,
                                'a1': 0})


acentuados = ['á', 'é', 'í', 'ó', 'ú', 'ã', 'õ', 'â', 'ê', 'î', 'ô', 'û', 'à', 'è', 'ì', 'ò', 'ù', 'ä', 'ë', 'ï', 'ö', 'ü', 'ç',
              'Á', 'É', 'Í', 'Ó', 'Ú', 'Ã', 'Õ', 'Â', 'Ê', 'Î', 'Ô', 'Û', 'À', 'È', 'Ì', 'Ò', 'Ù', 'Ä', 'Ë', 'Ï', 'Ö', 'Ü', 'Ç']

pontuacoes = [',', '.', ';', ':', '!', '?', '(', ')', '[', ']', '{', '}', '<', '>', '-', '_', '=', '+', '/', '\\', '|', '@', '#', '$', '%', '^', '&', '*']

list_chars = acentuados + pontuacoes + [' ']

data['distorted_text'] = data['req_text'].apply(lambda x: ''.join([char if char in list_chars else "*" for char in x]))

data.head()


data.to_csv('text_pos_pa.csv', index=False)


data.age.value_counts()








text = pd.read_csv('../classificador-texto/nb-texto-1000.csv')
pos = pd.read_csv('../classificador-pos-tag/nb-pos-tag-1000.csv')
pont_acent = pd.read_csv('../classificador-pont-acent/nb-pont-acent-1000.csv')





text.melhores_parametros.iloc[0]


best_params = {'vect__ngram_range': (1, 3),
               'selection__percentile': 100,
               'estimator__fit_prior': False,
               'estimator__alpha': 0.3}


pipeline = Pipeline([
                ('vect', TfidfVectorizer()),
                ('scaling', MaxAbsScaler()), 
                ('selection', SelectPercentile()),
                ('estimator', MultinomialNB())
                ])


text_clf = pipeline.set_params(**best_params)


text_clf.get_params


# a seguir os dados serão divididos entre features (X) e label (y)
X_text = data['req_text'] # features
y = data['age'] # label


X_train_text, X_test_text, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42,
                                                   stratify=y)


text_clf.fit(X_train_text, y_train)


text_clf.predict_proba(X_test_text)





pos.melhores_parametros.iloc[0]


best_params = {'vect__ngram_range': (3, 4),
               'selection__percentile': 100,
               'estimator__fit_prior': False,
               'estimator__alpha': 0.3}


pipeline = Pipeline([
                ('vect', TfidfVectorizer()),
                ('scaling', MaxAbsScaler()), 
                ('selection', SelectPercentile()),
                ('estimator', MultinomialNB())
                ])


pos_clf = pipeline.set_params(**best_params)


pos_clf.get_params


# a seguir os dados serão divididos entre features (X) e label (y)
X_pos = data['pos'] # features
y = data['age'] # label


X_train_pos, X_test_pos, y_train, y_test = train_test_split(X_pos, y, test_size=0.2, random_state=42,
                                                   stratify=y)


pos_clf.fit(X_train_pos, y_train)


pos_clf.predict_proba(X_test_pos)





pont_acent.melhores_parametros.iloc[0]


best_params = {'vect__ngram_range': (5, 6),
               'vect__analyzer': 'char',
               'estimator__fit_prior': False,
               'estimator__alpha': 0.02}


pipeline = Pipeline([
                ('vect', TfidfVectorizer()),
                ('scaling', MaxAbsScaler()), 
                ('selection', SelectPercentile()),
                ('estimator', MultinomialNB())
                ])


pa_clf = pipeline.set_params(**best_params)


pa_clf.get_params


# a seguir os dados serão divididos entre features (X) e label (y)
X_pa = data['distorted_text'] # features
y = data['age'] # label


X_train_pa, X_test_pa, y_train, y_test = train_test_split(X_pa, y, test_size=0.2, random_state=42,
                                                   stratify=y)


pa_clf.fit(X_train_pa, y_train)


pa_clf.predict_proba(X_test_pa)











prob_pa = pd.DataFrame(pa_clf.predict_proba(X_test_pa), columns=['prob_a1_pa', 'prob_a2_pa',
                                                                            'prob_a3_pa', 'prob_a4_pa'])

prob_pa





prob_text = pd.DataFrame(text_clf.predict_proba(X_test_text), columns=['prob_a1_text', 'prob_a2_text',
                                                                            'prob_a3_text', 'prob_a4_text'])
prob_text





prob_pos = pd.DataFrame(pos_clf.predict_proba(X_test_pos), columns=['prob_a1_pos', 'prob_a2_pos',
                                                                            'prob_a3_pos', 'prob_a4_pos'])
prob_pos





meta_clf_data = pd.concat([prob_pa, prob_text, prob_pos], axis=1)

meta_clf_data['age'] = pd.DataFrame(y_test).reset_index(drop=True)

meta_clf_data.head()


X_meta = meta_clf_data.drop(['age'], axis=1)
y_meta = meta_clf_data['age']


# Dividindo o conjunto de dados em treino e teste
X_train_meta, X_test_meta, y_train, y_test = train_test_split(X_meta, y_meta, test_size=0.2, random_state=42)

# Criando um modelo de Regressão Logística
meta_clf = LogisticRegression(random_state=42)

# Treinando o modelo
meta_clf.fit(X_train_meta, y_train)

# Fazendo previsões no conjunto de teste
previsoes = meta_clf.predict(X_test_meta)

# Avaliando a precisão do modelo
acuracia = accuracy_score(y_test, previsoes)
acuracia


print(classification_report(y_test, previsoes))
