
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier 
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.svm import LinearSVC
import nltk
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import RFECV, RFE, SelectKBest
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.model_selection import RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn import set_config
set_config(display='diagram')
from sklearn.svm import SVC
import datetime
from sklearn.ensemble import StackingClassifier

import shap


#imports
from time import time
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.svm import SVC
#from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import cross_val_score
import optuna
from sklearn.metrics import f1_score


import pandas as pd 

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import MaxAbsScaler
from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import RandomOverSampler
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import  classification_report
from sklearn.feature_selection import SelectPercentile
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize


import eli5





data = pd.read_csv('../../../../data/processed/(CORRIGIDO)ep2_pln_train_pos_pt_core_news_lg.xlsx')
data.drop(['Unnamed: 0'], axis=1, inplace=True)
data.head()


data['age'] = data['age'].map({
                                'a4':3,
                                'a3': 2,
                                'a2': 1,
                                'a1': 0})


data.head()


# a seguir os dados serão divididos entre features (X) e label (y)
X_text = data['req_text'] # features
y = data['age'] # label


X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42,
                                                   stratify=y)





best_params = {'vect__ngram_range': (1, 3),
               'selection__percentile': 100,
               'estimator__fit_prior': False,
               'estimator__alpha': 0.3}


# define o pipeline
pipeline = Pipeline([
        ('vect', TfidfVectorizer()),
        ('scaling', MaxAbsScaler()), 
        ('selection', SelectPercentile()),
        ('ros', RandomOverSampler(random_state=42)),
        ('estimator', MultinomialNB())
        ])


clf = pipeline.set_params(**best_params)


clf.get_params


clf.fit(X_train, y_train)











def show_most_informative_features(n=20):
    vectorizer = clf['vect']
    classifier = clf['estimator']
    feature_names = vectorizer.get_feature_names()
    coefs_with_fns = sorted(zip(classifier.coef_[0], feature_names))
    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])
    print ("\tfeatures preditivas menos relevantes\tfeatures preditivas mais relevantes")
    print ("\t------------------------------------\t------------------------------------")
    for (coef_1, fn_1), (coef_2, fn_2) in top:
        print ("\t%.4f\t%-15s\t\t%.4f\t%-15s" % (coef_1, fn_1, coef_2, fn_2))


show_most_informative_features()


def make_predictions(X_test):
    
    preds = clf.predict(X_test)
    
    return preds

masker = shap.maskers.Text(tokenizer=r"\W+")
explainer = shap.Explainer(make_predictions, masker=masker)

shap_values_global = explainer(X_text)


shap.plots.bar(shap_values.mean(0))





# Faça previsões no conjunto de teste
y_pred = clf.predict(X_test)

# Crie a matriz de confusão
conf_matrix = confusion_matrix(y_test, y_pred)

# Crie um heatmap usando seaborn
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', cbar=True,
            xticklabels=['a0', 'a1', 'a2', 'a3'],
            yticklabels=['a0', 'a1', 'a2', 'a3'])

plt.title('Matriz de Confusão')
plt.xlabel('Valores Preditos')
plt.ylabel('Valores Reais')
plt.show()





# Obtenha as probabilidades previstas para cada classe no conjunto de teste
y_score = clf.predict_proba(X_test)

# Binarize as classes para a construção da curva ROC
y_test_bin = label_binarize(y_test, classes=np.unique(y))

# Calcule a curva ROC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(len(np.unique(y))):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

classes = ['a0', 'a1', 'a2', 'a3']

# Plote a curva ROC para cada classe
plt.figure(figsize=(8, 8))
for i in range(len(np.unique(y))):
    plt.plot(fpr[i], tpr[i], lw=2, label=f'Classe {classes[i]} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falso Positivo (FPR)')
plt.ylabel('Taxa de Verdadeiro Positivo (TPR)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()





# Faça previsões no conjunto de teste
y_pred = clf.predict(X_test)

# Gere e imprima o relatório de classificação
report = classification_report(y_test, y_pred)
print("Relatório de Classificação:")
print(report)





shap.initjs()


def make_predictions(X_text):
    
    preds = clf.predict(X_text)
        
    return preds
# ---------------------------------------------------------- SE FOR CHAR PRECISA MUDAR O TOKENIZER
masker = shap.maskers.Text(tokenizer=r"\W+")
explainer = shap.Explainer(make_predictions, masker=masker)


amostra = X_test[0:20].reset_index(drop=True)
labels = y_test[0:20].reset_index(drop=True)
shap_values_local = explainer(amostra)





y_pred = clf.predict(amostra)
y_proba = clf.predict_proba(amostra)


y_pred = y_pred.astype(object)


y_pred[y_pred == 0] = 'a1'
y_pred[y_pred == 1] = 'a2'
y_pred[y_pred == 2] = 'a3'
y_pred[y_pred == 3] = 'a4'


labels[labels == 0] = 'a1'
labels[labels == 1] = 'a2'
labels[labels == 2] = 'a3'
labels[labels == 3] = 'a4'


y_pred


a1_idx = [i for i in range(len(y_pred)) if y_pred[i] == 'a1']
a2_idx = [i for i in range(len(y_pred)) if y_pred[i] == 'a2']
a3_idx = [i for i in range(len(y_pred)) if y_pred[i] == 'a3']
a4_idx = [i for i in range(len(y_pred)) if y_pred[i] == 'a4']





for i in a1_idx:

    print(f'A predição foi {y_pred[i]}')
    print(f'A label real era {labels[i]}')
    print(f'As probabilidades foram {y_proba[i]}')
    shap.text_plot(shap_values_local[i])
    print('--------------------------------------------------------------------------------------------------------------------')





for i in a2_idx:

    print(f'A predição foi {y_pred[i]}')
    print(f'A label real era {labels[i]}')
    print(f'As probabilidades foram {y_proba[i]}')
    shap.text_plot(shap_values_local[i])
    print('--------------------------------------------------------------------------------------------------------------------')





for i in a3_idx:

    print(f'A predição foi {y_pred[i]}')
    print(f'A label real era {labels[i]}')
    print(f'As probabilidades foram {y_proba[i]}')
    shap.text_plot(shap_values_local[i])
    print('--------------------------------------------------------------------------------------------------------------------')





for i in a4_idx:

    print(f'A predição foi {y_pred[i]}')
    print(f'A label real era {labels[i]}')
    print(f'As probabilidades foram {y_proba[i]}')
    shap.text_plot(shap_values_local[i])
    print('--------------------------------------------------------------------------------------------------------------------')





acertos = [i for i in range(len(y_pred)) if y_pred[i] == labels[i]]
erros = [i for i in range(len(y_pred)) if y_pred[i] != labels[i]]





for i in acertos:

    print(f'A predição foi {y_pred[i]}')
    print(f'A label real era {labels[i]}')
    print(f'As probabilidades foram {y_proba[i]}')
    shap.text_plot(shap_values_local[i])
    print('--------------------------------------------------------------------------------------------------------------------')





for i in erros:

    print(f'A predição foi {y_pred[i]}')
    print(f'A label real era {labels[i]}')
    print(f'As probabilidades foram {y_proba[i]}')
    shap.text_plot(shap_values_local[i])
    print('--------------------------------------------------------------------------------------------------------------------')





shap.plots.bar(shap_values_local)



